breakout1:
  env_id: "Breakout-v5"
  replay_memory_size: 50_000  # Reduced from 1M to 50K for memory efficiency
  mini_batch_size: 64
  min_buffer_size: 50_000  # Wait until buffer is populated before training
  update_freq: 4  # Train every 4 steps
  epsilon_init: 1
  epsilon_decay: 0.999996
  epsilon_min: 0.05
  network_sync_rate: 10_000
  learning_rate_a: 0.0001
  discount_factor_g: 0.99
  stop_on_reward: 100_000
  enable_double_dqn: True
  enable_dueling_dqn: True

breakout1.1:
  env_id: "Breakout-v5"
  replay_memory_size: 200000    # Much smaller buffer for faster updates
  mini_batch_size: 32          # Larger batch for more efficient GPU usage
  min_buffer_size: 50_000  # Wait until buffer is populated before training
  update_freq: 4  # Train every 4 steps
  epsilon_init: 1
  epsilon_decay: 0.9995         # useless since linear decay is used
  epsilon_min: 0.1            # Lower minimum epsilon
  network_sync_rate: 10000      # More frequent target updates
  learning_rate_a: 0.0001       # Higher learning rate for faster learning
  discount_factor_g: 0.99
  stop_on_reward: 100000
  enable_double_dqn: True
  enable_dueling_dqn: True
  exploration_steps: 1000000     # Linear epsilon schedule over 1m steps

# Medium post configuration - matches the blog implementation exactly
breakout3.1:
  env_id: "Breakout-v5"
  replay_memory_size: 300_000   # Medium post uses 500k (reduced from 1M)
  mini_batch_size: 32           # Batch size 32
  min_buffer_size: 50_000       # Wait until 50k samples before training
  update_freq: 4                # Train every 4 steps
  epsilon_init: 1.0
  epsilon_min: 0.1              # Decay from 1.0 to 0.1
  epsilon_decay: 0.9995         # Not used (linear schedule takes precedence)
  network_sync_rate: 10_000     # Target network update every 10k steps
  learning_rate_a: 0.0001       # Adam optimizer with lr=0.0001
  discount_factor_g: 0.99       # Gamma = 0.99
  stop_on_reward: 1000           # Stop when reaching 1000 reward
  enable_double_dqn: True       # Double DQN enabled
  enable_dueling_dqn: True      # Dueling DQN enabled
  exploration_steps: 150_000  # Linear epsilon decay over 150k steps

